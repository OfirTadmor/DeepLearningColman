{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/OfirTadmor/DeepLearningColman/blob/Task4/IMDB_CNN.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "M4lJZloHwGWM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 522
        },
        "outputId": "d505d058-e8b3-4318-de2f-4273fe2ae06d"
      },
      "cell_type": "code",
      "source": [
        "import numpy\n",
        "from keras.datasets import imdb\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM, Convolution1D, Flatten, Dropout\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.preprocessing import sequence\n",
        "from keras.callbacks import TensorBoard\n",
        "\n",
        "\n",
        "# Using keras to load the dataset with the top_words\n",
        "top_words = 10000\n",
        "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=top_words)\n",
        "\n",
        "# Pad the sequences to the same length\n",
        "max_review_length = 1600\n",
        "X_train = sequence.pad_sequences(X_train, maxlen=max_review_length)\n",
        "X_test = sequence.pad_sequences(X_test, maxlen=max_review_length)\n",
        "\n",
        "# Using embedding from Keras\n",
        "embedding_vecor_length = 300\n",
        "model = Sequential()\n",
        "model.add(Embedding(top_words, embedding_vecor_length, input_length=max_review_length))\n",
        "\n",
        "# Convolutional model (3x conv, flatten, 2x dense)\n",
        "model.add(Convolution1D(64, 3, padding='same'))\n",
        "model.add(Convolution1D(32, 3, padding='same'))\n",
        "model.add(Convolution1D(16, 3, padding='same'))\n",
        "model.add(Flatten())\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(180,activation='sigmoid'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(1,activation='sigmoid'))\n",
        "\n",
        "# Log to tensorboard\n",
        "#tensorBoardCallback = TensorBoard(log_dir='./logs', write_graph=True)\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "print(model.summary())\n",
        "\n",
        "#model.fit(X_train, y_train, epochs=3, callbacks=[tensorBoardCallback], batch_size=64)\n",
        "model.fit(X_train, y_train, epochs=3, batch_size=64)\n",
        "\n",
        "# Evaluation on the test set\n",
        "scores = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 1600, 300)         3000000   \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 1600, 64)          57664     \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 1600, 32)          6176      \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 1600, 16)          1552      \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 25600)             0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 25600)             0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 180)               4608180   \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 180)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 181       \n",
            "=================================================================\n",
            "Total params: 7,673,753\n",
            "Trainable params: 7,673,753\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/3\n",
            " 3776/25000 [===>..........................] - ETA: 7:46 - loss: 0.6640 - acc: 0.6171"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "16576/25000 [==================>...........] - ETA: 3:03 - loss: 0.4204 - acc: 0.7997"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}